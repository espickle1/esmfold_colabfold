{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlOoMQv9cAvvBMEQS5J8H3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/espickle1/esmfold_colabfold/blob/main/ESMFold_ColabFold_second.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpxAvRtxZxrX"
      },
      "outputs": [],
      "source": [
        "### Colabfold running ESMFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Install necessary packages\n",
        "%%time\n",
        "version = \"1\"\n",
        "model_name = \"esmfold_v0.model\" if version == \"0\" else \"esmfold.model\"\n",
        "\n",
        "import os, time\n",
        "\n",
        "if not os.path.isfile(model_name):\n",
        "  # download esmfold params\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(f\"aria2c -q -x 16 https://colabfold.steineggerlab.workers.dev/esm/{model_name} &\")\n",
        "\n",
        "  if not os.path.isfile(\"finished_install\"):\n",
        "    # install libs\n",
        "    print(\"installing libs...\")\n",
        "    os.system(\"pip install -q omegaconf pytorch_lightning biopython ml_collections einops py3Dmol modelcif\")\n",
        "    os.system(\"pip install -q git+https://github.com/NVIDIA/dllogger.git\")\n",
        "\n",
        "    print(\"installing openfold...\")\n",
        "    # install openfold\n",
        "    os.system(f\"pip install -q git+https://github.com/sokrypton/openfold.git\")\n",
        "\n",
        "    print(\"installing esmfold...\")\n",
        "    # install esmfold\n",
        "    os.system(f\"pip install -q git+https://github.com/sokrypton/esm.git\")\n",
        "    os.system(\"touch finished_install\")\n",
        "\n",
        "  # wait for Params to finish downloading...\n",
        "  while not os.path.isfile(model_name):\n",
        "    time.sleep(5)\n",
        "  if os.path.isfile(f\"{model_name}.aria2\"):\n",
        "    print(\"downloading params...\")\n",
        "  while os.path.isfile(f\"{model_name}.aria2\"):\n",
        "    time.sleep(5)"
      ],
      "metadata": {
        "id": "jthGQKfGZ1ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import dependencies\n",
        "import torch\n",
        "from jax.tree_util import tree_map\n",
        "import gc\n",
        "\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "import hashlib, re, os\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "import py3Dmol\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "A7cyvhSZZ3iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Parsing outputs and get unique hash\n",
        "def parse_output(output):\n",
        "  pae = (output[\"aligned_confidence_probs\"][0] * np.arange(64)).mean(-1) * 31\n",
        "  plddt = output[\"plddt\"][0,:,1]\n",
        "\n",
        "  bins = np.append(0,np.linspace(2.3125,21.6875,63))\n",
        "  sm_contacts = softmax(output[\"distogram_logits\"],-1)[0]\n",
        "  sm_contacts = sm_contacts[...,bins<8].sum(-1)\n",
        "  xyz = output[\"positions\"][-1,0,:,1]\n",
        "  mask = output[\"atom37_atom_exists\"][0,:,1] == 1\n",
        "  o = {\"pae\":pae[mask,:][:,mask],\n",
        "       \"plddt\":plddt[mask],\n",
        "       \"sm_contacts\":sm_contacts[mask,:][:,mask],\n",
        "       \"xyz\":xyz[mask]}\n",
        "  return o\n",
        "\n",
        "def get_hash(x): return hashlib.sha1(x.encode()).hexdigest()"
      ],
      "metadata": {
        "id": "cJtnYl8SZ7px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load model\n",
        "if \"model\" not in dir() or model_name != model_name_:\n",
        "  if \"model\" in dir():\n",
        "    # delete old model from memory\n",
        "    del model\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  model = torch.load(model_name)\n",
        "  model.eval().cuda().requires_grad_(False)\n",
        "  model_name_ = model_name"
      ],
      "metadata": {
        "id": "DPsKQP0AaCAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import as a function\n",
        "def sequence_read(sequence_input, position, copies):\n",
        "  sequence = sequence_input.loc[position]['Translation']\n",
        "  sequence_clean = re.sub(\"[^A-Z:]\", \"\", sequence.replace(\"/\",\":\").upper())\n",
        "  sequence_clean = re.sub(\":+\",\":\",sequence)\n",
        "  sequence_clean = re.sub(\"^[:]+\",\"\",sequence)\n",
        "  sequence_clean = re.sub(\"[:]+$\",\"\",sequence)\n",
        "\n",
        "  meta = sequence_input.loc[position]['meta']\n",
        "\n",
        "  if copies == \"\" or copies <= 0: copies = 1\n",
        "  sequence = \":\".join([sequence] * copies)\n",
        "\n",
        "  ID = \"Number_\" + str(position) + \"_\" + jobname+\"_\"+get_hash(sequence)[:5]\n",
        "  seqs = sequence.split(\":\")\n",
        "  lengths = [len(s) for s in seqs]\n",
        "  length = sum(lengths)\n",
        "  print(\"length\",length)\n",
        "\n",
        "  u_seqs = list(set(seqs))\n",
        "  if len(seqs) == 1: mode = \"mono\"\n",
        "  elif len(u_seqs) == 1: mode = \"homo\"\n",
        "  else: mode = \"hetero\"\n",
        "\n",
        "  return sequence_clean, meta, copies, ID, u_seqs, length, lengths"
      ],
      "metadata": {
        "id": "F-o5Z2O7aDuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Predict protein structure from input sequence\n",
        "def prediction_block(sequence, ID, row_number):\n",
        "  start_time = time.time()\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  output = model.infer(\n",
        "      sequence,\n",
        "      num_recycles=num_recycles,\n",
        "      chain_linker=\"X\"*chain_linker,\n",
        "      residue_index_offset=512\n",
        "      )\n",
        "\n",
        "  pdb_str = model.output_to_pdb(output)[0]\n",
        "  output = tree_map(lambda x: x.cpu().numpy(), output)\n",
        "  ptm = output[\"ptm\"][0]\n",
        "  plddt = output[\"plddt\"][0,...,1].mean()\n",
        "  O = parse_output(output)\n",
        "  print(f'ptm: {ptm:.3f} plddt: {plddt:.3f}')\n",
        "\n",
        "  end_time = time.time()\n",
        "  print(f\"Inference time for entry {row_number}, {meta}: {end_time - start_time:.2f}s\")\n",
        "\n",
        "  # os.system(f\"mkdir -p {ID}\")\n",
        "  prefix = f\"{ID}_ptm{ptm:.3f}_r{num_recycles}_default\"\n",
        "  np.savetxt(f\"{prefix}.pae.txt\",O[\"pae\"],\"%.3f\")\n",
        "  with open(f\"{prefix}.pdb\",\"w\") as out:\n",
        "    out.write(pdb_str)\n",
        "\n",
        "  return pdb_str, prefix, O"
      ],
      "metadata": {
        "id": "YcThVBCJaFHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import settings: manual settings\n",
        "alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "\n",
        "num_recycles = 3\n",
        "chain_linker = 25\n",
        "multimer_n = 1\n",
        "row_number = 6\n",
        "\n",
        "jobname = \"dir_test\"\n",
        "jobname = re.sub(r'\\W+', '', jobname)[:50]\n",
        "\n",
        "input_directory = \"/content/drive/MyDrive/ww_virome/esmfold_colab/sequences/\"\n",
        "output_directory = \"/content/drive/MyDrive/ww_virome/esmfold_colab/structures\"\n",
        "os.chdir(output_directory)\n",
        "file_path = f\"{input_directory}big_merge_norovirus_translation.csv\"\n",
        "sequence_file = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# memory.free [MiB] A100: 40506 MiB -\n",
        "# memory.free [MiB] L4: 22692 MiB - 1000\n",
        "# memory.free [MiB]T4: 15095 MiB - 700\n",
        "\n",
        "# length = len(sequence)\n",
        "# if length > 700:\n",
        "#   model.set_chunk_size(64)\n",
        "# else:\n",
        "#   model.set_chunk_size(128)\n",
        "\n",
        "total_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 2)  # Convert to MiB\n",
        "free_memory = total_memory * 0.8  # Assume 80% available\n",
        "\n",
        "if free_memory > 20000:  # 20 GB+\n",
        "    chunk_size = 256\n",
        "elif free_memory > 10000:  # 10-20 GB (T4, 15GB)\n",
        "    chunk_size = 128\n",
        "else:\n",
        "    chunk_size = 64  # Low VRAM GPUs\n",
        "\n",
        "model.set_chunk_size(chunk_size)\n",
        "print(f\"Using chunk_size: {chunk_size}\")"
      ],
      "metadata": {
        "id": "nQZ7NeD4aG6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "sequence_clean, meta, copies, ID, u_seqs, length, lengths = sequence_read(\n",
        "    sequence_file,\n",
        "    row_number,\n",
        "    copies=multimer_n\n",
        "    )\n",
        "\n",
        "pdb_str, prefix, O = prediction_block(\n",
        "    sequence_clean,\n",
        "    ID,\n",
        "    row_number\n",
        "    )"
      ],
      "metadata": {
        "id": "lf_QIjAMaMdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}